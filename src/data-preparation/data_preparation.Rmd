---
title: "Data Exploration"
subtitle: "SKILLS: Data Preparation and Workflow Management - Group 9"
author:
  - "Rabino Tommaso"
  - "Franceschini Emanuele"
  - "Magalotti Bianca"
  - "Tan Colin"
  - "Benmrit Akram"
date: "\\textit{20 October 2024}"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 2
    number_sections: true
    fig_caption: true
header-includes:
  - "\\usepackage[english]{babel}"  # Language
  - "\\usepackage[T1]{fontenc}"  # Font encoding
  - "\\usepackage{mathptmx}"  # Times New Roman font for text
  - "\\usepackage{helvet}"  # Arial-like font for sans-serif
  - "\\usepackage{setspace}"  # Line spacing
  - "\\onehalfspacing"  # 1.5 line spacing
  - "\\usepackage{fancyhdr}"  # Header and footer customization
  - "\\usepackage{titlesec}"  # Section titles formatting
  - "\\usepackage{abstract}"  # Abstract formatting
  - "\\usepackage{caption}"  # Captions customization
  - "\\usepackage{graphicx}"  # Graphics
  - "\\usepackage{amsmath}"  # Math equations
  - "\\usepackage{amssymb}"  # Math symbols
  - "\\usepackage{natbib}"  # Citation style (change as needed)
  - "\\bibliographystyle{apalike}"  # Bibliography style (change as needed)
  - "\\usepackage{hyperref}"  # Hyperlinks and URLs
  - "\\hypersetup{colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue}"
  - "\\usepackage{appendix}"  # Appendix formatting
  - "\\usepackage{enumerate}"  # Enumerate environment
  - "\\pagestyle{fancy}"  # Custom page style
  - "\\fancyhf{}"
  - "\\renewcommand{\\headrulewidth}{0pt}"
  - "\\renewcommand{\\footrulewidth}{0pt}"
  - "\\fancyhead[R]{\\thepage}"  # Page number in the header
  - "\\fancypagestyle{plain}{\\fancyhf{}\\renewcommand{\\headrulewidth}{0pt}}"
  - "\\lhead{\\small{A.A. 2023/2024-Courses: SKILLS: Data Preparation and Workflow Management}}"
  - "\\usepackage{multicol}"  # For two columns
geometry: "left=2.5cm, right=1.5cm, top=2.5cm, bottom=2.5cm"  # Adjust margins
---

```{r, include=FALSE}
knitr::opts_chunk$set(tidy = FALSE,
                      size = "small",
                      out.width = "100%",
                      message = FALSE,
                      warning = FALSE,
                      error = FALSE)
```


```{r, include = FALSE}
###############################################################
#############             PACKAGES               ##############
###############################################################
#GENERAL PACKAGES:
library(tidyverse) #A "Package of Packages" for Data manipulation and visualization (includes magrittr, lubridate, purrr, tidyr, etc.).
library(dplyr) #Data frame manipulations (select, slice, etc.
library(jsonlite) #For Amenities Columns Creation

#PLOT PACKAGES:
library(ggplot2) #Building fancy plots.
library(ggthemes) #Themes for ggplots (e.g. "solarized").
library(ggcorrplot) #For correlograms
library(scales) #Scaling and formatting ggplots (e.g. scale_fill_gradient()).
library(gt) #Latex tables
```


```{r, echo=FALSE}
# Load the R object
clean_data <- readRDS("../../gen/data-preparation/input/clean_data.rds")
```

In this R fil we will prepare the dataset for the subsequent modelling of the regression. Indeed, although through the previous analyses we have managed to avoid many of the problems typical of regression models (e.g. presence of outliers, presence of missing data, predictors reduction, etc.), we still have a few steps left to perform before constructing our regression model.
All these data preparation operations will be performed in the following sections. 


\section{Correlations to handle multicollinearity}
Here is a correlogram displaying correlation values for all numeric variables and \texttt{price}.
```{r, include=FALSE}
corr_data <- clean_data %>% dplyr::select_if(is.numeric)

corr_matrix <- round(cor(corr_data),2)

# Define custom color palette
my_colors <- c("#E6E6E6", "#FFFFFF", "#CCCCCC")

# Restyled correlogram plot
p13 <- ggcorrplot(corr_matrix,
           hc.order = FALSE,
           method = "square",
           type = "lower",
           outline.col = "white",
           colors = my_colors,
           lab = TRUE, 
           lab_size = 2.5,
           digits = 2,
           tl.cex = 8,
           title = "Apartment-related Correlogram") +
  theme(legend.position = "none", 
        plot.title = element_text(lineheight = 2, face = "bold", vjust = 1, hjust = 0.5, color = "#333333"),
        plot.subtitle = element_text(color = "#666666", vjust = 1, hjust = 0.5),
        axis.title = element_text(color = "#666666"), 
        axis.text = element_text(color = "#666666"))

```

```{r, echo=FALSE}
p13
```

To improve clarity, we created a table displaying the pairs of numeric variables with a mutual correlation higher than 0.75. Additionally, we've organized the variables in descending order based on their mutual correlation to enhance interpretation.
Thi table helps in identifying highly correlated variables for potential removal to avoid multicollinearity in regression analysis.
```{r, include=FALSE}
# Convert correlation matrix into a dataframe
corr_matrix_df <- data.frame(corr_matrix)

# Add a new column for variable names
corr_matrix_df$Variable <- row.names(corr_matrix_df)

# Define the threshold for correlation
threshold <- 0.75

# Create a data frame to store pairs of highly correlated variables
high_corr_pairs <- data.frame(Variable1 = character(0), Variable2 = character(0), Correlation = numeric(0))

# Loop through the rows and columns of the correlation matrix
for (i in 1:nrow(corr_matrix)) {
  for (j in 1:ncol(corr_matrix)) {
    if (i < j && abs(corr_matrix[i, j]) > threshold) {
      high_corr_pairs <- rbind(high_corr_pairs, 
                               data.frame(Variable1 = rownames(corr_matrix)[i],
                                          Variable2 = colnames(corr_matrix)[j],
                                          Correlation = corr_matrix[i, j]))
    }
  }
}

#Arrange order: 
high_corr_pairs <- high_corr_pairs %>% arrange(desc(high_corr_pairs$Correlation))

t17 <- high_corr_pairs %>%
  gt() %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_header(
    title = "Highly Correlated Variable Pairs",
    subtitle = paste("Pairs with correlation > ", threshold),
  )

```

```{r, echo=FALSE}
t17
```


The code snippet below is utilized to eliminate one variable from the \texttt{clean\_data} dataframe for each pair of highly correlated variables previously identified. The criterion for removal is to discard the variable with the lowest correlation with \texttt{price}. Between the highly correlated variables, we decided to retain only beds, accommodates, and bedroom, since their very high correlation with \texttt{price}.
```{r}
clean_data <- clean_data %>% dplyr::select(-host_total_listings_count, -availability_90, -availability_30, -review_scores_value, -review_scores_accuracy, -reviews_per_month, -review_scores_checkin)
```


```{r, include=FALSE}
rm(corr_data, corr_matrix, p8, t12, corr_matrix_df, my_colors, i, j, threshold, high_corr_pairs)
```






\section{Dealing with skewness of price}
First of all, we have to <span style="color: #D4AF37;">__prepare our response variable for the modeling__</span>, because its skewness it's too high. 

> __Skewness__ is a measure of the symmetry in a distribution. A symmetrical variable will have a skewness equal to 0 (i.e. a normal distributed variable will have a skewness of 0). As a rule of thumb, a variable can be regarded as __sufficiently normally distributed if its skewness is near to 0__ or, at least, between -1 and 1.











```{r}
cat("As we can see, the skewness of our target variable (price) is too high: ", skewness(raw_data$price))
```

In order to fix this issue, __we computed the logarithm in base 10 of the price__ and use it as __response variable__ of our regression model.

```{r}
raw_data$log_price = log10(raw_data$price)
cat("The skewness of our new response variable (log_price) is equal to: ", skewness(raw_data$log_price), "--> a much better result than the previous one.")
```

It is also possible to <span style="color: #D4AF37;">__measure the improvement in the skewness of our dependent variable__</span> by inspecting the __two Normal Q-Q plots below__. As we know, a Normal Q-Q (Quantile-Quantile) plot is a graphical tool used to assess whether or not a variable is approximately normally distributed. The plot compares the observed data quantiles to the expected quantiles of a normal distribution.

Indeed, it can be seen that __our response variable is now better normally distributed__, since the points better follow the straight line drawn at a 45-degree angle from the origin.

```{r, fig.show="hold", out.width="50%"}
par(mfrow=c(2,1))

ggplot(raw_data, aes(sample = price)) +
  stat_qq(color = "#AC001E") +
  stat_qq_line(color = "#9A7B4F", size=1) +
  labs(title = "Normal Q-Q Plot of Price",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles")+
  theme(legend.position = "none", 
        plot.title = element_text(size = 18, lineheight=.8, face="bold", vjust=1, hjust=0.5, colour = "#AC001E"),
        plot.subtitle = element_text(size = 12, lineheight=.8, vjust=1, hjust=0.5, colour = "#AC001E"),
        axis.title = element_text(size = 14, colour = "#AC001E"), 
        axis.text = element_text(size = 8, colour = "#666666"),
        axis.text.x = element_text(hjust = 1),
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"))
  
ggplot(raw_data, aes(sample = log_price)) +
  stat_qq(color = "#AC001E") +
  stat_qq_line(color = "#9A7B4F", size=1) +
  labs(title = "Normal Q-Q Plot of Log_price",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles")+
  theme(legend.position = "none", 
        plot.title = element_text(size = 18, lineheight=.8, face="bold", vjust=1, hjust=0.5, colour = "#AC001E"),
        plot.subtitle = element_text(size = 12, lineheight=.8, vjust=1, hjust=0.5, colour = "#AC001E"),
        axis.title = element_text(size = 14, colour = "#AC001E"), 
        axis.text = element_text(size = 8, colour = "#666666"),
        axis.text.x = element_text(hjust = 1),
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"))


par(mfrow=c(1,1))

raw_data <- raw_data %>% dplyr::select(-price)
  
```  


### Second Step - Divide the dataset based on variables 'format' {.unnumbered}
With the following scripts we __divided the dataset into 3 parts__: one for numeric variables, one for date variables, and one for factor variables. This passage is important because __we will manage each of this part separately__ in the following data preparation sections. Specifically:

* <span style="color: #D4AF37;">__Numeric Variables__</span>: The numeric Variables (except for the response variable _price_) will be __centered__ and __scaled__ to avoid error due to different scales.
* <span style="color: #D4AF37;">__Date and Factor Variables__</span>: Since XGBoost Regression Models can only handle numerical variables, _factor_ and _date_ predicotrs will be __converted into numeric format__ by using two different methods.

```{r}
numeric_raw_data <- raw_data %>% dplyr::select_if(is.numeric)
date_raw_data <- raw_data %>% dplyr::select_if(is.Date)
factor_raw_data <- raw_data %>% dplyr::select_if(is.factor)

Numeric_Variables <- names(numeric_raw_data)
Date_Variables <- names(date_raw_data)
Factor_Variables <- names(factor_raw_data)

cat("There are", length(numeric_raw_data), "numeric variables,", length(date_raw_data), "date variables, and", length(factor_raw_data), "factor variables. And they are the following: ")

Numeric_Variables %>%
  kbl(col.names = "Numeric Variables",
      align = "c") %>%
  kable_paper("hover", full_width = F)%>%
  scroll_box(height = "200px")

Date_Variables %>%
  kbl(col.names = "Date Variables",
      align = "c") %>%
  kable_paper("hover", full_width = F)

Factor_Variables %>%
  kbl(col.names = "Factor Variables",
      align = "c") %>%
  kable_paper("hover", full_width = F)%>%
  scroll_box(height = "200px")


rm(Numeric_Variables, Date_Variables, Factor_Variables)
```


### Third Step - Managing 'Date' Predictors {.unnumbered}
In order to convert the <span style="color: #D4AF37;">__'date' variables in 'numeric' format__</span> we created 3 different new variables, one for the days, one for the months, and one for the years for each of the 4 date variables. 
The following, is a glimpse of our newly created variables. 

```{r}
date_raw_data$last_scraped_day <- as.numeric(day(date_raw_data$last_scraped))
date_raw_data$last_scraped_month <- as.numeric(month(date_raw_data$last_scraped))
date_raw_data$last_scraped_year <- as.numeric(year(date_raw_data$last_scraped))

date_raw_data$host_since_day <- as.numeric(day(date_raw_data$host_since))
date_raw_data$host_since_month <- as.numeric(month(date_raw_data$host_since))
date_raw_data$host_since_year <- as.numeric(year(date_raw_data$host_since))

date_raw_data$first_review_day <- as.numeric(day(date_raw_data$first_review))
date_raw_data$first_review_month <- as.numeric(month(date_raw_data$first_review))
date_raw_data$first_review_year <- as.numeric(year(date_raw_data$first_review))

date_raw_data$last_review_day <- as.numeric(day(date_raw_data$last_review))
date_raw_data$last_review_month <- as.numeric(month(date_raw_data$last_review))
date_raw_data$last_review_year <- as.numeric(year(date_raw_data$last_review))

date_raw_data <- date_raw_data %>% dplyr::select(-last_scraped, -host_since, -first_review, -last_review)

head(date_raw_data, 5)%>%
  kbl(align = "c") %>%
  kable_paper("hover", full_width = F)
```



### Fourth Step - Centering and Scaling Numeric Predictor {.unnumbered}
In order to avoid errors due to the different scales used to measure the numeric variables, we performed two different operations, namely <span style="color: #D4AF37;">__centering__</span> and <span style="color: #D4AF37;">__scaling__</span> numeric predictors.

> __Centering__ refers to the process of __subtracting the mean value of a numeric variable from each value of that variable__. This transformation results in a new variable with a mean of zero. Centering is useful when we want to compare the relative position of different observations, without being affected by the scale of the original variable.

> __Scaling__, on the other hand, refers to the process of transforming a numeric variable so that its values fall within a specific range or interval. Scaling techniques can be used to normalize variables and reduce the impact of extreme values, making them more comparable. For example, a commonly used scaling technique is __standardization__, where __each value is subtracted by the mean and divided by the standard deviation__, resulting in a new variable with a mean of zero and standard deviation of one. Another example is min-max scaling, where each value is subtracted by the minimum value and divided by the range, resulting in a new variable with values between 0 and 1.

In order to perform these two operations we employed the _preProcess()_ function fo the _caret_ package. Moreover, since we want to scale and center only predictors, we have taken out the target variable from the dataset.

Before centering and scaling numeric predictors, we stored the mean and the standard deviation of some variables into distinct vectors in order to use them in the conclusion section.

```{r}
############### NEEDED FOR THE CONCLUSION #####################################################

accommodates_mean <- mean(numeric_raw_data$accommodates)
accommodates_sd <- sd(numeric_raw_data$accommodates)
bedrooms_mean <- mean(numeric_raw_data$bedrooms)
bedrooms_sd <- sd(numeric_raw_data$bedrooms)
beds_mean <- mean(numeric_raw_data$beds)
beds_sd <- sd(numeric_raw_data$beds)
host_listings_count_mean <- mean(numeric_raw_data$host_listings_count)
host_listings_count_sd <- sd(numeric_raw_data$host_listings_count)

###############################################################################################


y <- numeric_raw_data$log_price

numeric_raw_data <- numeric_raw_data %>%
  dplyr::select (-log_price)

preprocessed_data <- preProcess(numeric_raw_data, method=c("center", "scale"))

print(preprocessed_data)

numeric_raw_data <- predict(preprocessed_data, newdata = numeric_raw_data)

rm(preprocessed_data)
```


### Fifth Step - Managing Factor Predictors {.unnumbered}
In order to train a regression model using categorical predictors, we have to __convert them in 'numeric' format__. For doing so we used a method called <span style="color: #D4AF37;">__'One-Hot Encoding'__</span>. 

> One-hot encoding is a process of __converting categorical or factor__ variables into a __set of binary (0/1) variables__ that can be used in a machine learning model. In this process, each category of the factor variable is represented as a separate binary variable or column. <br>


For instance, take as an example the variable _host_verifications_ wich has three categories: _phone_, _e-mail_, and _work e-mail_. After one-hot encoding, we create three new binary variables: _host_verifications_phone_, _host_verifications_email_, and _host_verifications_workemail_. For each observation, the binary variable corresponding to the observed host_verifications is set to 1, and all others are set to 0.

As said, one-hot encoding is necessary because __most machine learning algorithms cannot directly handle categorical variables__. By converting categorical variables into binary variables, we allow machine learning algorithms to treat each category as a separate feature, and to learn unique relationships between each category and the outcome variable.

```{r}
factor_raw_data <- as.data.frame(model.matrix(~.-1, factor_raw_data))

head(factor_raw_data, 5)%>%
  kbl(align = "c") %>%
  kable_paper("hover", full_width = F)
```


### Sixth Step - Combine the sub-datasets {.unnumbered}
Then, we __combined the 3 sub-datasets__ (factor_raw_data, numeric_raw_data and date_raw_data) that __now contain only numeric variables__ and that now have been centered and scaled.

```{r}
rm(raw_data)

raw_data <- cbind(factor_raw_data, numeric_raw_data, date_raw_data)

cat("Now, our dataset has ", nrow(raw_data), "observations and ", ncol(raw_data), "variables")

rm(factor_raw_data, numeric_raw_data, date_raw_data)

head(raw_data, 5)%>%
  kbl(align = "c") %>%
  kable_paper("hover", full_width = F)
```






























