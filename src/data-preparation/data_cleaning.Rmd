---
title: "Data Cleansing"
subtitle: "SKILLS: Data Preparation and Workflow Management - Group 9"
author:
  - "Rabino Tommaso"
  - "Franceschini Emanuele"
  - "Magalotti Bianca"
  - "Tan Colin"
  - "Benmrit Akram"
date: "\\textit{20 October 2024}"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 2
    number_sections: true
    fig_caption: true
header-includes:
  - "\\usepackage[english]{babel}"  # Language
  - "\\usepackage[T1]{fontenc}"  # Font encoding
  - "\\usepackage{mathptmx}"  # Times New Roman font for text
  - "\\usepackage{helvet}"  # Arial-like font for sans-serif
  - "\\usepackage{setspace}"  # Line spacing
  - "\\onehalfspacing"  # 1.5 line spacing
  - "\\usepackage{fancyhdr}"  # Header and footer customization
  - "\\usepackage{titlesec}"  # Section titles formatting
  - "\\usepackage{abstract}"  # Abstract formatting
  - "\\usepackage{caption}"  # Captions customization
  - "\\usepackage{graphicx}"  # Graphics
  - "\\usepackage{amsmath}"  # Math equations
  - "\\usepackage{amssymb}"  # Math symbols
  - "\\usepackage{natbib}"  # Citation style (change as needed)
  - "\\bibliographystyle{apalike}"  # Bibliography style (change as needed)
  - "\\usepackage{hyperref}"  # Hyperlinks and URLs
  - "\\hypersetup{colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue}"
  - "\\usepackage{appendix}"  # Appendix formatting
  - "\\usepackage{enumerate}"  # Enumerate environment
  - "\\pagestyle{fancy}"  # Custom page style
  - "\\fancyhf{}"
  - "\\renewcommand{\\headrulewidth}{0pt}"
  - "\\renewcommand{\\footrulewidth}{0pt}"
  - "\\fancyhead[R]{\\thepage}"  # Page number in the header
  - "\\fancypagestyle{plain}{\\fancyhf{}\\renewcommand{\\headrulewidth}{0pt}}"
  - "\\lhead{\\small{A.A. 2023/2024-Courses: SKILLS: Data Preparation and Workflow Management}}"
  - "\\usepackage{multicol}"  # For two columns
geometry: "left=2.5cm, right=1.5cm, top=2.5cm, bottom=2.5cm"  # Adjust margins
---



```{r, include=FALSE}
knitr::opts_chunk$set(tidy = FALSE,
                      size = "small",
                      out.width = "100%",
                      message = FALSE,
                      warning = FALSE,
                      error = FALSE)
```


```{r, include = FALSE}
###############################################################
#############             PACKAGES               ##############
###############################################################
#GENERAL PACKAGES:
library(tidyverse) #A "Package of Packages" for Data manipulation and visualization (includes magrittr, lubridate, purrr, tidyr, etc.).
library(dplyr) #Data frame manipulations (select, slice, etc.
library(jsonlite) #For Amenities Columns Creation

#PLOT PACKAGES:
library(ggplot2) #Building fancy plots.
library(ggthemes) #Themes for ggplots (e.g. "solarized").
library(scales) #Scaling and formatting ggplots (e.g. scale_fill_gradient()).
library(gt) #Latex tables
```


```{r}
# Load the R object
raw_data <- readRDS("../../gen/data-preparation/input/raw_data.rds")
```


\newpage
\section{Introduction}
In this document, the data manipulation procedures applied to the original dataset are outlined. These procedures encompass the incorporation of new features, the conversion of variables into alternative formats, and the data cleansing process. These manipulations are indispensable for assuring the quality and appropriateness of the dataset for constructing the regression model.

\begin{enumerate}
    \item[\Roman{enumi}I.] Management of Empty Columns: Removal of the variables \texttt{calendar\_updated}, \texttt{neighbourhood\_group\_cleansed} and \texttt{bathrooms} from the dataset due to their sole containment of missing values.
        \item[\Roman{enumi}II.] Management of Unnecessary Variables: Elimination of variables that lack relevance to our regression model, such as \texttt{listing\_url}.
    \item[\Roman{enumi}III.] Management of Observations with Missing Values: Ultimate elimination of all observations containing missing values (NAs) across any variables within the dataset, acknowledging the incompatibility of regression models and correlations with missing data.
    \item[\Roman{enumi}IV.] Management of Price Outliers: Subsequent removal of observations with outliers in the \texttt{price} variable, as it serves as the dependent variable (DV) in our regression model.
    \item[\Roman{enumi}V.] Management of Character Variables: Conversion of specific variables from a "character" format to "date" and "factor" formats to ensure compatibility with our regression model, which exclusively accommodates "factor" and "numeric" formats.
    \item[\Roman{enumi}VI.] Management of the Amenities Variable: Utilization of the \texttt{amenities} variable to generate a series of Boolean variables, indicating the provision of specific services within a listing, including "pool," "gym," "garden," "elevator," "oven," and more.
    \item[\Roman{enumi}VII.] Management of Factor Variables: Removal of certain levels within the \texttt{property\_type} and \texttt{neighbourhood\_cleansed} (factor) variables, characterized by minimal observations, to alleviate the computational burden of our regression model.
\end{enumerate}

\section{Management of empty columns}
Code for showing the number of columns that contains only missing values:

```{r}
cols_to_remove <- sapply(raw_data, function(x) all(is.na(x)))
indices <- which(unlist(cols_to_remove))
names_list <- names(cols_to_remove)[indices]
cat('There are only', length(names_list), 'columns with only missing values')
```

Code for extracting the names of columns with only missing values: 
```{r}
cat('Names of columns with only missing values:', names_list)
```

Code for removing columns with only missing values: 
```{r}
raw_data <- raw_data %>%
  select(-which(cols_to_remove))
```

As can be seen from the output below, once \texttt{calendar\_updated}, \texttt{neighbourhood\_group\_cleansed} and \texttt{bathroom} have been removed, there are no other columns containing only NAs. 

```{r}
cols_to_remove <- sapply(raw_data, function(x) all(is.na(x)))
indices <- which(unlist(cols_to_remove))
names_list <- names(cols_to_remove)[indices]
cat("Now, there are", length(names_list), "columns containing only missing values")
```


```{r, include=FALSE}
rm(indices, cols_to_remove, names_list)
```


\section{Management of unnecessary variables}
During this phase of the project, the 'select' function was utilized to identify and exclude variables that were deemed irrelevant for our price prediction analysis. The selection of variables for removal was made in accordance with the following criteria, with a focus on minimizing the number of exclusions:

\begin{enumerate}
    \item[\Roman{enumi}I.] Format Criteria: The majority of removed variables were in 'character' format.
    \item[\Roman{enumi}II.] Usefulness Criteria: Removal of variables that were clearly irrelevant for predicting listings' prices.
    \item[\Roman{enumi}III.] Redundancy Criteria: Removal of variables that overlapped each other and carried the same information (this was also to avoid multicollinearity, more on this later in this project).
    \item[\Roman{enumi}IV.] Consistency Criteria: Removal of variables present only in certain data sets.
\end{enumerate}

Following these guidelines, we chose to remove the following variables:
```{r, include=FALSE}
# Create a data frame with your itemized list
itemized_list <- data.frame(
  Variable = c(
    "id", "listing_url", "scrape_id", "last_scraped", "source",
    "name", "description", "neighborhood_overview", "picture_url",
    "host_id", "host_url", "host_name", "host_location", "host_about",
    "host_thumbnail_url", "host_picture_url", "host_neighbourhood",
    "neighbourhood", "minimum_minimum_nights", "maximum_minimum_nights",
    "minimum_maximum_nights", "maximum_maximum_nights",
    "minimum_nights_avg_ntm", "maximum_nights_avg_ntm",
    "calendar_last_scraped", "license",
    "calculated_host_listings_count",
    "calculated_host_listings_count_entire_homes",
    "calculated_host_listings_count_private_rooms",
    "calculated_host_listings_count_shared_rooms"
  ),
  Description = c(
    "unique identifier for the listing",
    "URL of the listing",
    "ID of the data scrape",
    "last update of data set",
    "source from which the listing information were scraped",
    "title of the ad placed by the host on the AirBnb platform",
    "brief description of the listing",
    "brief description of the neighborhood",
    "URL of listings' pictures",
    "unique identifier for hosts",
    "URL of the host",
    "name of the host",
    "city of hosts' residence",
    "brief description of the hosts",
    "URL of the hosts' thumbnail pictures",
    "URL of the hosts' pictures",
    "host's neighborhood",
    "neighborhood (neighbourhood_cleansed was more informative)",
    "to avoid redundancy",
    "to avoid redundancy",
    "to avoid redundancy",
    "to avoid redundancy",
    "to avoid redundancy",
    "to avoid redundancy",
    "to avoid redundancy",
    "to avoid redundancy",
    "to avoid redundancy",
    "to avoid redundancy",
    "to avoid redundancy",
    "to avoid redundancy"
  )
)

t2 <- itemized_list %>%
  gt() %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_header(
    title = "Variables to Remove"
  )

```

```{r, echo=FALSE}
t2
```

```{r, include=FALSE}
rm(t2, itemized_list)
```



The following code, which implies the use of the \texttt{select} function, is used to remove those variables: 
```{r}
raw_data <- raw_data %>%
  dplyr::select (-id, -listing_url, -scrape_id, -last_scraped, -source, -name, -description, -neighborhood_overview, -picture_url, -host_id, -host_url, -host_name, -host_location, -host_about, -host_thumbnail_url, -host_picture_url,-host_neighbourhood, -neighbourhood, -minimum_minimum_nights, -maximum_minimum_nights, -minimum_maximum_nights, -maximum_maximum_nights, -minimum_nights_avg_ntm, -maximum_nights_avg_ntm, -calendar_last_scraped, -license, -calculated_host_listings_count, -calculated_host_listings_count_entire_homes, -calculated_host_listings_count_private_rooms, -calculated_host_listings_count_shared_rooms)
```

The following character variables remain. Subsequent scripts will address these variables.  
```{r}
char_cols <- names(raw_data[,sapply(raw_data, is.character)])
cat('There are', length(char_cols), 'columns in character format and they are the following:')
```


```{r, include=FALSE}
char_cols <- data.frame(Variable = char_cols)

t3 <-char_cols %>%
  gt() %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_header(
    title = "Character Variables",
    subtitle = "List of Remaining Character Variables",
  )
```

```{r, echo=FALSE}
t3
```

```{r, include=FALSE}
rm(t3)
```



\section{Management of Observations with Missing Values}
After completing the previous data cleaning operation, the removal of observations containing missing values (i.e., NAs) is warranted.

This step holds significance as many regression model functions in R are incompatible with observations featuring missing values. Furthermore, eliminating missing values, if a sufficient number of observations remain, generally enhances model performance.

\textbf{Inspecting the number of missing values:} First, the following code was used to determine the number of rows having at least one missing value: 
```{r}
cat('Now, there are', sum(!complete.cases(raw_data)), 'rows with at least 1 NAs regarding the variables we chose to maintain in the dataset')
```

\textbf{Missing Values per Variable Dataframe:} The subsequent code was employed to generate a two-column dataframe called \texttt{missing\_data}. Its first column contains the variable names from the \texttt{raw\_data} dataset, while the second column displays the number of missing values for each variable.

```{r}
missing_data <- raw_data %>%
  summarize_all(~ sum(is.na(.))) %>%
  gather() %>%
  rename(variable = key, missing_values = value)

missing_data <- missing_data %>%
  filter(missing_values > 0) %>%
  arrange(desc(missing_values)) 

missing_data$variable <- reorder(missing_data$variable, missing_data$missing_values)
```

The previously generated dataframe \texttt{missing\_data} is shown below. By inspecting the table, it is possible to notice that the majority of variables with missing values are in \textit{numeric} format. Most of these belong to the "review-related" variables. Other numeric variables containing missing values include 'bedrooms,' 'beds,' and \texttt{review\_per\_month}. 
```{r, include=FALSE}
t5 <- missing_data %>%
  gt() %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_header(
    title = "Table of Missing Values",
    subtitle = "Number of Missing Values by Variable",
  )
```

```{r, echo=FALSE}
t5
```


\textbf{Plot of Missing Values per Variable:} The subsequent plot illustrates the number of missing values per variable:
```{r, include=FALSE}
p5 <- ggplot(data = missing_data, aes(x = variable, y = missing_values, fill = missing_values)) +
  geom_bar(stat = "identity") +
  scale_fill_gradient(low = "lightgrey", high = "black") +
  geom_label(aes(label = missing_values), fill = "#666666", col = "white", size = 3) +
  labs(title = "Number of Missing Values per Variable",
       subtitle = "Data collected from Listings dataset",
       x = "Variables",
       y = "Number of Missing Values") +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(size = 18, lineheight = 0.8, face = "bold", vjust = 1, hjust = 0.5, colour = "black"),
        plot.subtitle = element_text(size = 12, lineheight = 0.8, vjust = 1, hjust = 0.5, colour = "black"),
        axis.title = element_text(size = 14, colour = "black"),
        axis.text = element_text(size = 8, colour = "black"),
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white")) +
  coord_flip()
```

```{r, echo=FALSE}
p5
```

```{r, include=FALSE}
rm(t5, p5, missing_data)
```


\textbf{Managing Missing Values:} Initially, an attempt was made to impute the median and the mean (of the respective variables) for all missing values within the 'numeric' and 'date' variables. However, this imputation approach led to a notable decline in the regression model's performance.

Therefore, as a final decision, the choice was made to eliminate all observations containing missing data from the dataset, since the number of observations remained in the dataset was sufficient. 

The following code shows how to remove those observations from the dataset:
```{r}
raw_data <- na.omit(raw_data)
cat('Now, there are', sum(!complete.cases(raw_data)), 'rows with NAs in the dataset')
```

\section{Management of price outliers}
In the initial phase of our analysis, emphasis was placed on addressing the presence of outliers within our dataset, particularly among numerical predictors. It is noteworthy that while the absence of outliers is often considered a beneficial practice for enhancing regression model performance, it does not represent an absolute requirement for regression analysis. Given this perspective, we directed our attention specifically to outliers within our response variable, which is the listings' \texttt{price}.

To explore potential strategies for handling outliers, we conducted experiments involving the replacement of outliers with both the mean and median values of the \texttt{price} variable. However, these approaches yielded unsatisfactory outcomes, leading to a decline in the overall performance of the final model.

Consequently, we made the decision to adopt a straightforward approach: the removal of observations exhibiting outliers concerning the \texttt{price} variable. Following an initial exploratory analysis, it was determined that listings with prices exceeding the 99th percentile would be excluded from the dataset.

The initial step in this process involved converting the \texttt{price} variable into a numeric format, which also entailed the removal of all non-numeric characters, such as dollar signs and commas. The code snippet below illustrates the procedure:
```{r}
raw_data <- raw_data %>%
  mutate(price = as.numeric(str_replace_all(price, "[^0-9.]", "")))
str(raw_data$price)
```

Outliers within the \texttt{price} variable are readily discernible through visual examination of \texttt{Figure 1} and \texttt{Figure 2}, illustrating the distribution of the \texttt{price} variable.

Conforming to the principles of regression analysis, where the presence of outliers contravenes underlying assumptions, a systematic removal process was applied to eliminate such data points from our dataset prior to model construction.

```{r, include=FALSE}
# Plot 1: Histogram
p1 <- ggplot(raw_data, aes(price)) +
  geom_histogram(binwidth = 100, col = "darkgrey", fill = alpha("grey", 0.5)) +
  scale_y_log10() +
  scale_x_continuous(labels = dollar_format(), n.breaks = 5) +
  labs(x = "Price",
       y = "Number of Listings",
       caption = element_text("Figure 1", color = "black"),
       title = element_text("Number of Listings by Price Class", color = "black"),
       subtitle = element_text("Data collected from Listings dataset", color = "black")) +
  theme_minimal() +
  theme(text = element_text(family = "serif"),
        plot.title = element_text(size = 16, hjust = 0.5, color = "black"),
        plot.subtitle = element_text(size = 12, hjust = 0.5, color = "black"),
        axis.title = element_text(size = 14, color = "black"),  # Black axis title
        axis.text = element_text(size = 12, color = "black"),  # Black axis text
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"))

# Plot 2: Box Plot
p2 <- ggplot(raw_data, aes(y = price)) +
  geom_boxplot(varwidth = TRUE, col = "darkgrey", fill = alpha("grey", 0.5)) +
  scale_y_continuous(labels = dollar_format(), n.breaks = 5) +
  labs(title = element_text("Box Plot of Listings by Price Class", color = "black"),
       subtitle = element_text("Data collected from Listings dataset", color = "black"),
       caption = element_text("Figure 2", color = "black"),
       x = NULL,
       y = "Price") +
  theme_minimal() +
  theme(text = element_text(family = "serif"),
        plot.title = element_text(size = 16, hjust = 0.5, color = "black"),
        plot.subtitle = element_text(size = 12, hjust = 0.5, color = "black"),
        axis.title = element_text(size = 14, color = "black"),  # Black axis title
        axis.text = element_text(size = 12, color = "black"),  # Black axis text
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white")) +
  coord_flip()
```


```{r, echo=FALSE}
p1
p2
```

```{r, include=FALSE}
rm(p1, p2)
```


As illustrated in the table below, a significant proportion of outliers are situated beyond the 99th percentile threshold. Consequently, prior to model construction, the decision was made to exclude these listings from our dataset.
```{r}
# Create the table
price_percentiles <- quantile(raw_data$price, c(0.50, 0.75, 0.80, 0.90, 0.95, 0.96, 0.97, 0.98, 0.99, 0.999, 1))

df_percentiles <- data.frame(percentile_range = names(price_percentiles), 
                             price = price_percentiles,
                             row.names = NULL)

```

```{r, include = FALSE}
# Style the table
t1 <- df_percentiles %>%
  gt() %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_header(
    title = "Table of Percentiles",
    subtitle = "Average Price by Percentile Range",
  ) 
```

```{r, echo=FALSE}
t1
```

```{r, include=FALSE}
rm(t1)
```


The subsequent code demonstrates the procedure for eliminating observations from the dataset whose prices exceed the 99th percentile:
```{r}
raw_data <- raw_data %>%
  dplyr::filter (price <= quantile(raw_data$price, probs = c(0.99)))
```

With the removal of outliers surpassing the 99th percentile, there is a notable enhancement in the distribution of prices among apartments, as evident in \texttt{Figures 3} and in \texttt{Figure 4}:


```{r, include = FALSE}

# Plot 3: Histogram
p3 <- ggplot(raw_data, aes(price)) +
  geom_histogram(binwidth = 100, col = "darkgrey", fill = alpha("grey", 0.5)) +
  scale_y_log10() +
  scale_x_continuous(labels = dollar_format(), n.breaks = 5) +
  labs(x = "Price",
       y = "Number of Listings",
       title = element_text("Number of Listings by Price Class", color = "black"),
       caption = element_text("Figure 3", color = "black"),
       subtitle = element_text("Data collected from Listings dataset", color = "black")) +
  theme_minimal() +
  theme(text = element_text(family = "serif"),
        plot.title = element_text(size = 16, hjust = 0.5, color = "black"),
        plot.subtitle = element_text(size = 12, hjust = 0.5, color = "black"),
        axis.title = element_text(size = 14, color = "black"),  # Black axis title
        axis.text = element_text(size = 12, color = "black"),  # Black axis text
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"))

# Plot 4: Box Plot
p4 <- ggplot(raw_data, aes(y = price)) +
  geom_boxplot(varwidth = TRUE, col = "darkgrey", fill = alpha("grey", 0.5)) +
  scale_y_continuous(labels = dollar_format(), n.breaks = 5) +
  labs(title = element_text("Box Plot of Listings by Price Class", color = "black"),
       subtitle = element_text("Data collected from Listings dataset", color = "black"),
       caption = element_text("Figure 4", color = "black"),
       x = NULL,
       y = "Price") +
  theme_minimal() +
  theme(text = element_text(family = "serif"),
        plot.title = element_text(size = 16, hjust = 0.5, color = "black"),
        plot.subtitle = element_text(size = 12, hjust = 0.5, color = "black"),
        axis.title = element_text(size = 14, color = "black"),  # Black axis title
        axis.text = element_text(size = 12, color = "black"),  # Black axis text
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white")) +
  coord_flip()


rm(price_percentiles, df_percentiles)
```

```{r, echo=FALSE}
p3
p4
```

```{r, include=FALSE}
rm(p3, p4)
```


The enhancement in the distribution of the \texttt{price} variable is also discernible from the subsequent output, presenting a summary of the variable's statistics:
```{r}
summary(raw_data$price)
```


\section{Management of character variables}
These scripts was used for the conversion of specific variables from character to date and factor formats, a crucial step to ensure the compatibility of our dataset with regression analysis.

The transformation of these variables holds significance as character variables would have imposed limitations on the scope of our model. These conversions now enable the incorporation of these variables into our regression analysis, expanding the analytical possibilities of our study.

\textbf{Date Variables:} Code for converting 'character' variable into 'date' format: 
```{r}
date_cols <- c("host_since", "first_review", "last_review")
raw_data <- raw_data %>%
  mutate_at(vars(all_of(date_cols)), ~as.Date(., format = "%Y-%m-%d"))
```

```{r, include=FALSE}
rm(date_cols)
```

\textbf{Numeric Variables 1:} Code for handling the \texttt{host\_response\_rate} and \texttt{host\_acceptance\_rate} variables involved several steps. Initially, we substituted "N/A" with "0%", following which we eliminated the '%' symbols. Subsequently, we altered the variables to a numeric format and concluded by modifying the variable names, appending "_percentage."

The decision to replace "N/A" with "0%" was founded on the realization that these particular observations did not indicate missing values. Instead, the absence of data regarding the host's response and acceptance rates stemmed from the host's recent enrollment, rendering this information currently unavailable (Refer to the InsideAirBnb documentation for additional information on this topic). 

```{r}
raw_data <- raw_data %>%
  mutate_at(vars(host_response_rate, host_acceptance_rate), ~gsub("N/A", "0%", .)) %>%
  mutate_at(vars(host_response_rate, host_acceptance_rate), ~as.numeric(gsub("%", "", .))) %>%
  rename(host_response_rate_percentage = host_response_rate, host_acceptance_rate_percentage = host_acceptance_rate)
```

\textbf{Numeric Variables 2:} The processing of the bathrooms_text variable encompassed multiple steps. Initially, extraneous text was eliminated, retaining only the actual number of bathrooms. Subsequently, the column underwent a conversion to a numeric format. Finally, the variable name was changed to "bathroom."

```{r}
raw_data <- raw_data %>%
  mutate(bathrooms_text = gsub("[^0-9.]", "", bathrooms_text)) %>%
  mutate(bathrooms = as.double(bathrooms_text)) %>%
  select(-bathrooms_text) %>%
  na.omit()
```

\textbf{Factor Variables:} The remaining 'character' variables were systematically transformed into 'factor' format using the following code:

```{r}
factor_cols <- c(
  "host_response_time", "host_is_superhost", "host_verifications",
  "host_has_profile_pic", "host_identity_verified", "neighbourhood_cleansed",
  "room_type", "property_type", "instant_bookable", "has_availability")

raw_data <- raw_data %>%
  mutate_at(vars(all_of(factor_cols)), as.factor)
```

```{r, include=FALSE}
rm(factor_cols)
```


As shown below, presently only one 'character' variable remains. Subsequent scripts will address this variable as well.
```{r}
char_cols <- raw_data %>% 
  select_if(is.character) %>% 
  names()

cat('Now, there is only', length(char_cols), 'column in character format and it is the following:', char_cols)
```

\section{Management of the Amenities Variable}
Within the dataset, the 'amenities' column serves as a character variable, cataloging the services offered by individual listings to their tenants, encompassing amenities such as "Air Conditioning," "Elevator," "Refrigerator," and "Wifi." To systematically determine the presence or absence of these specific services within each apartment, a structured sequence of operations was undertaken:

\begin{enumerate}
  \item[\Roman{enumi}I.] \textbf{Data Pre-Processing:} Data preprocessing is necessary to convert the 'amenities' column into a format suitable for analysis.
    \begin{enumerate}
      \item[\alph{enumii}] Conversion to Word Lists: The code starts by converting the \texttt{amenities} column of JSON-like text into a list of words. This step is essential to prepare the data for further analysis.
      \item[\alph{enumii}] Combining Word Lists: All the word lists from the 'amenities' column are combined into a single list named 'all\_words.' This consolidation simplifies the subsequent frequency analysis.
    \end{enumerate}
  \item[\Roman{enumi}II.] \textbf{Amenity Frequency Analysis:} Filtering frequently occurring amenities focuses the analysis on the most relevant data, preventing an overwhelming number of binary columns.
    \begin{enumerate}
      \item[\alph{enumii}] Counting Amenities: The code calculates the frequency of each unique amenity in the 'all\_words' list, resulting in 'amenity\_counts.' This step provides insights into how often each amenity appears in the dataset.
      \item[\alph{enumii}] Frequency-Based Filtering: To optimize the utility of the generated binary columns, a thoughtful filtering process was executed. Specifically, amenities appearing at least 1,000 times were selected for binary column creation. This selection criterion was chosen to prioritize commonly offered amenities while simplifying the dataset's structure and avoiding the creation of an excessively large number of binary columns.
    \end{enumerate}
  \item[\Roman{enumi}III.] \textbf{Amenity Binary Column Creation:} The for loop at the end of the code block streamlines the process of determining amenity presence, by providing clear indicators of amenity presence or absence in each listing.
    \begin{enumerate}
      \item[\alph{enumii}] Creating Binary Columns: First, the loop creates, for each amenity that met the filtering criteria, a new binary column in the dataset raw\_data.
      \item[\alph{enumii}] Amenity Presence Check: Then, the loop employes the function grepl() to check whether a specific amenity is present in the 'amenities' column of each listing. It returns "YES" if the amenity is found and "NO" if it's not. Finally, the newly created and populated columns are converted into a factor format.
    \end{enumerate}
\end{enumerate}

```{r}
# Convert the column from JSON-like text to a list of words
word_lists <- lapply(raw_data$amenities, function(x) fromJSON(x, simplifyVector = TRUE))

# Combine all word lists into one
all_words <- unlist(word_lists)

# Create a dataframe to count unique words
unique_word_counts <- data.frame(Word = unique(all_words),
                                 Count = table(all_words)[unique(all_words)])

# Filter amenities that appear at least 1000 times
frequent_amenities <- unique_word_counts %>%
  filter(Count.Freq >= 1000)

# Loop through each word in frequent_amenities
for (word in frequent_amenities$Word) {
  # Create a new column in raw_data with the word as the column name
  col_name <- gsub("[^[:alnum:] ]", "", word)  # Remove non-alphanumeric characters except spaces
  col_name <- gsub(" ", "_", col_name)  # Replace spaces with underscores

  raw_data[[col_name]] <- factor(ifelse(grepl(word, raw_data$amenities), "YES", "NO"), levels = c("YES", "NO"))
}

```

```{r, include=FALSE}
rm(frequent_amenities, unique_word_counts, word_lists, all_words, word, col_name)
```


In the earlier process of creating binary columns for various amenities, it's possible that not all newly created columns are relevant. This can occur when a specific amenity has not been found in any of the listings, resulting in columns with only one level, rendering them effectively constant.

To address this, we need to identify and remove these irrelevant amenity columns from our dataset. This cleaning step ensures that we retain only the binary columns corresponding to amenities that are actually present in the dataset. The following code accomplishes this task:

```{r}
# Identify factor variables in the dataset
factor_vars <- sapply(raw_data, is.factor)

# Apply droplevels to all factor variables
raw_data[factor_vars] <- lapply(raw_data[factor_vars], droplevels)

# Identify factor variables with only one level
constant_factors <- sapply(raw_data, function(x) length(levels(x)) == 1)

# Select the constant factor variables
constant_factor_vars <- raw_data[, constant_factors]

# Remove the constant factor variables from the original dataset
raw_data <- raw_data[, !constant_factors]
```

```{r, include=FALSE}
rm(constant_factor_vars, constant_factors, factor_vars)
```


The following is an example of the newly created columns:

```{r, include=FALSE}
# Select the columns you want to display
selected_cols <- head(raw_data, 5) %>%
  dplyr::select(43:47)

# Create a gt table
t4 <- gt(selected_cols)

# Apply styling to the table headers (making them bold)
t4 <- t4 %>%
  tab_header(
    title = "Selected Columns",
    subtitle = "Example of newly created columns from amenities"
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())
  )
```

```{r, echo=FALSE}
# Print the table
t4
```

```{r, include=FALSE}
# Remove the table object if needed
rm(t4, selected_cols)
```


Now that the utilization of the \texttt{amenities} variable has been completed (resulting in its transformation into a set of boolean variables in 'factor' format), it is advisable to remove it from the dataset. This action aligns with the earlier decision to eliminate all variables in 'character' format.

```{r}
raw_data <- raw_data %>% dplyr::select(-amenities)
```

At this point, it becomes evident that there are no remaining variables in 'character' format. Consequently, it can be affirmed that the final objective has been successfully achieved.   

```{r}
char_cols <- raw_data %>% 
  select_if(is.character) %>% 
  names()
cat('Now, there are', length(char_cols), 'column in character format.')
```

```{r, include=FALSE}
rm(char_cols)
```


\section{Management of factor variables}
The purpose of this section is to explore and manage the variables in factor format present in the dataset.

\subsection{Host\_response\_time}
In the context of the variable \texttt{host\_response\_time}, despite the previous removal of all observations with missing values within the dataset, it's noteworthy that there are still 15276 observations containing a value equal to \texttt{N\/A}.

```{r}
# Count the number of observations for each level of the "host_response_time" variable
table(raw_data$host_response_time)
```

This code is used to filter and remove observations that contain a value equal \texttt{N\/A} in the \texttt{host\_response\_time} variable, effectively cleaning the dataset from these particular instances.

```{r}
# Remove observations with "empty strings"N/A" in the "host_response_time" variable
raw_data <- raw_data %>%
  filter(host_response_time != "N/A")
```

Finally, the "N/A" level from the \texttt{host\_response\_time} variable is removed to ensure that it no longer appears in the levels of the factor variable, making the dataset more concise and accurate.
```{r}
# Remove the "empty cell" level from the host_is_superhost variable
raw_data$host_response_time <- droplevels(raw_data$host_response_time)
```

It is possible to notice that the \texttt{host\_response\_time} variable has now only four levels. 
```{r}
# Count the number of observations for each level of the "host_is_superhost" variable
table(raw_data$host_response_time)
```

\subsection{Host\_is\_superhost}
Similarly as before, in the context of the variable \texttt{host\_is\_superhost}, despite the previous removal of all observations with missing values within the dataset, it's noteworthy that there are still 4724 empty cells. This happens because the consideration of empty cells (empty strings) as missing values varies based on the data setup in R. Typically, R treats missing values as NA or NULL, while empty strings are regarded as valid data, not missing. Consequently, empty strings within your dataset are not automatically categorized as missing values.

It is possible to verify this by using the following code, which counts the number of observations for each level of the "host_is_superhost" variable.

```{r}
# Count the number of observations for each level of the "host_is_superhost" variable
table(raw_data$host_is_superhost)
```

This code is used to filter and remove observations that contain empty strings in the \texttt{host\_is\_superhost}  variable. By executing this code, we eliminate rows where the \texttt{host\_is\_superhost}  value is an empty string, effectively cleaning the dataset from these particular instances.

```{r}
# Remove observations with empty strings in the "host_is_superhost" variable
raw_data <- raw_data %>%
  filter(host_is_superhost != "")
```

Finally, the "empty cell" level from the \texttt{host\_is\_superhost} variable was removed to ensure that it no longer appears in the levels of the factor variable, making the dataset more concise and accurate.
```{r}
# Remove the "empty cell" level from the host_is_superhost variable
raw_data$host_is_superhost <- droplevels(raw_data$host_is_superhost)
```

It is possible to notice that the \texttt{host\_is\_superhost} variable has now only two levels. 
```{r}
# Count the number of observations for each level of the "host_is_superhost" variable
table(raw_data$host_is_superhost)
```

\subsection{Host\_verifications}
Initially, the \texttt{host\_verifications}  variable held values containing square brackets and apostrophes, potentially hindering subsequent analysis. Utilizing the \texttt{gsub} function, those special characters were eliminated from the variable's values. Furthermore, it's worth noting that the use of \texttt{gsub} automatically transformed the variable into a \texttt{character} format, necessitating a subsequent conversion back to \texttt{factor}.

```{r}
# Remove all characters except for letters and words from the host_verifications variable
raw_data$host_verifications <- gsub("[^a-zA-Z ]", "", raw_data$host_verifications)

# Convert host_verifications to factor
raw_data$host_verifications <- as.factor(raw_data$host_verifications)
```

As before, regarding the variable \texttt{host\_verifications}, despite the previous removal of all observations with missing values within the dataset, it's noteworthy that there are still 25 empty cells.
```{r}
# Count the number of observations for each level of the "host_verifications" variable
table(raw_data$host_verifications)
```

This code is used to filter and remove observations that contain empty strings in the \texttt{host\_verifications} variable. By executing this code, we eliminate rows where the \texttt{host\_verifications} value is an empty string, effectively cleaning the dataset from these particular instances.

```{r}
# Remove observations with empty strings in the "host_verifications" variable
raw_data <- raw_data %>%
  filter(host_verifications != "")
```

Finally, the "empty cell" level from the \texttt{host\_verifications} variable was removed to ensure that it no longer appears in the levels of the factor variable, making the dataset more concise and accurate.
```{r}
# Remove the "empty cell" level from the host_verifications variable
raw_data$host_verifications <- droplevels(raw_data$host_verifications)
```

It is possible to notice that the \texttt{host\_verifications} variable has now only two levels. 
```{r}
# Count the number of observations for each level of the "host_is_superhost" variable
table(raw_data$host_verifications)
```

\subsection{Property\_Type}
As can be noticed from the table below, the variable \texttt{property\_type} exhibits some levels with a notably low frequency of observations. Specifically, the table shows the levels of the \texttt{property\_tpe} variable with a frequency lower than 4. 
```{r, include=FALSE}
grouped_data <- raw_data %>%
  dplyr::group_by(property_type) %>%
  summarise(count=n())%>%
  arrange(count)%>%
  filter(count <= 4)

t6 <- head(grouped_data, 10) %>%
  gt() %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_header(
    title = "Table of Grouped Data",
    subtitle = "Count by Property Type (<= 4 Occurrences)",
  )
```

```{r, echo=FALSE}
t6
```

To optimize the computational efficiency of our regression model in predicting listing prices, the decision was made to eliminate \texttt{property\_type} levels containing fewer than four observations. 

The following is the code used to accomplish the aformentioned task.
```{r}
levels_to_remove <- grouped_data %>%
  pull(property_type)

raw_data <- anti_join(raw_data, data.frame(property_type = levels_to_remove), by = "property_type")

levels_to_drop <- levels(raw_data$property_type)[table(raw_data$property_type) == 0]

raw_data$property_type <- droplevels(raw_data$property_type, levels_to_drop)
```

```{r, include=FALSE}
rm(grouped_data, levels_to_drop, levels_to_remove, t6)
```



\subsection{Neighbourhood\_cleansed}
In a manner similar to the previous step, the table below illustrates that the \texttt{neighbourhood\_cleansed} variable exhibits several levels with a notably low frequency of observations. In this case too, the table shows the levels of the \texttt{neighbourhood\_cleansed} variable with a frequency lower than 4.

```{r}
grouped_data <- raw_data %>% 
  dplyr::group_by(neighbourhood_cleansed) %>% 
  dplyr::summarize(count = n()) %>%
  dplyr::arrange(count) %>%
  dplyr::filter(count <= 4)

t7 <- head(grouped_data, 10) %>%
  gt() %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_header(
    title = "Table of Grouped Data",
    subtitle = "Count by Neighbourhood (<= 4 Occurrences)",
  )
```

```{r, echo=FALSE}
t7
```

Therefore, as done before for the \texttt{property\_type} variable, in order to reduce the computational time required by our regression model to predict listings prices, it was decided to remove the \texttt{neighbourhood\_cleansed} levels with less than 4 observations. 

```{r}
levels_to_remove <- grouped_data %>%
  pull(neighbourhood_cleansed)

raw_data <- anti_join(raw_data, data.frame(neighbourhood_cleansed = levels_to_remove), by = "neighbourhood_cleansed")

levels_to_drop <- levels(raw_data$neighbourhood_cleansed)[table(raw_data$neighbourhood_cleansed) == 0]

raw_data$neighbourhood_cleansed <- droplevels(raw_data$neighbourhood_cleansed, levels_to_drop)
```

```{r, include=FALSE}
rm(levels_to_remove, grouped_data, levels_to_drop, t7)
```


In conclusion, the cleaned dataset is preserved for future purposes. It is stored as an RDS file, so that it will retain all the data manipulation steps, including variable format conversions.
```{r}
# Save raw_data as an R object
saveRDS(raw_data, file = "../../gen/data-preparation/input/clean_data.rds")
```

```{r, include=FALSE}
rm(raw_data)
```

