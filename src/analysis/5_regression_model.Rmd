---
title: "XGBoost Regression Model"
subtitle: "SKILLS: Data Preparation and Workflow Management - Group 9"
author:
  - "Rabino Tommaso"
  - "Franceschini Emanuele"
  - "Magalotti Bianca"
  - "Tan Colin"
  - "Benmrit Akram"
date: "\\textit{20 October 2024}"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 2
    number_sections: true
    fig_caption: true
header-includes:
  - "\\usepackage[english]{babel}"  # Language
  - "\\usepackage[T1]{fontenc}"  # Font encoding
  - "\\usepackage{mathptmx}"  # Times New Roman font for text
  - "\\usepackage{helvet}"  # Arial-like font for sans-serif
  - "\\usepackage{setspace}"  # Line spacing
  - "\\onehalfspacing"  # 1.5 line spacing
  - "\\usepackage{fancyhdr}"  # Header and footer customization
  - "\\usepackage{titlesec}"  # Section titles formatting
  - "\\usepackage{abstract}"  # Abstract formatting
  - "\\usepackage{caption}"  # Captions customization
  - "\\usepackage{graphicx}"  # Graphics
  - "\\usepackage{amsmath}"  # Math equations
  - "\\usepackage{amssymb}"  # Math symbols
  - "\\usepackage{natbib}"  # Citation style (change as needed)
  - "\\bibliographystyle{apalike}"  # Bibliography style (change as needed)
  - "\\usepackage{hyperref}"  # Hyperlinks and URLs
  - "\\hypersetup{colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue}"
  - "\\usepackage{appendix}"  # Appendix formatting
  - "\\usepackage{enumerate}"  # Enumerate environment
  - "\\pagestyle{fancy}"  # Custom page style
  - "\\fancyhf{}"
  - "\\renewcommand{\\headrulewidth}{0pt}"
  - "\\renewcommand{\\footrulewidth}{0pt}"
  - "\\fancyhead[R]{\\thepage}"  # Page number in the header
  - "\\fancypagestyle{plain}{\\fancyhf{}\\renewcommand{\\headrulewidth}{0pt}}"
  - "\\lhead{\\small{A.A. 2023/2024-Courses: SKILLS: Data Preparation and Workflow Management}}"
  - "\\usepackage{multicol}"  # For two columns
geometry: "left=2.5cm, right=1.5cm, top=2.5cm, bottom=2.5cm"  # Adjust margins
---

```{r, include=FALSE}
knitr::opts_chunk$set(tidy = FALSE,
                      size = "small",
                      out.width = "100%",
                      message = FALSE,
                      warning = FALSE,
                      error = FALSE)
```


```{r, include = FALSE}
#GENERAL PACKAGES:
library(readr)
library(tidyverse) #A "Package of Packages" for Data manipulation and visualization (includes magrittr, lubridate, purrr, tidyr, etc.).
library(dplyr) #Data frame manipulations (select, slice, etc.
library(jsonlite) #For Amenities Columns Creation
library(moments) #Measuring the skewness.

#REGRESSION PACKAGES
library(caret) #Hyperparameters Tuning. 
library(xgboost) #XGBoost Regression. 
library(DALEX) #Summary of the XGBoost Regression Model ("explainer).
library(bayesforecast) #Checking Regression Assumptions.

#SHINYAPP PACKAGES
library(shiny) #For the ShinyApp
library(shinyWidgets) #For the ShinyApp

#PLOT AND FIGURES PACKAGES:
library(ggplot2) #Building fancy plots.
library(ggthemes) #Themes for ggplots (e.g. "solarized").
library(ggcorrplot) #For correlograms
library(scales) #Scaling and formatting ggplots (e.g. scale_fill_gradient()).
library(gt) #Latex tables

# WORKING DIRECTORY SETTING PACKAGES
library(here)
library(rstudioapi)
```

```{r, include=FALSE}
# Get the path of the active document
current_document_path <- getActiveDocumentContext()$path

# Check if the document path is set
if (!is.null(current_document_path)) {
  # Set the working directory to the source file's location
  setwd(dirname(current_document_path))
  
  # Optionally, you can remove the document path variable
  rm(current_document_path)
} else {
  cat("No active document or path found. Set working directory manually.\n")
}
```

```{r, echo=FALSE}
# Load the R object
regression_data <- readRDS("../../gen/analysis/input/regression_data.rds")
y <- readRDS("../../gen/analysis/input/y.rds")
```

\section{Introduction}
We have now reached the central phase of our work, wherein we will guide you through the steps involved in constructing a robust XGBoost regression model for predicting Airbnb listing prices.

This section is organized into the following key segments:
\begin{enumerate}
    \item[\Roman{enumi}I.] Dataset Splitting: In the initial stage, we undertake the division of the original dataset into a training dataset (containing 75\% of observations) and a testing dataset /containing the remaining 25\% of observations).
    \item[\Roman{enumi}II.] Modeling: In the second part, we will focus on the modeling process. This involves hyperparameter tuning, determining the optimal number of iterations, training the model, and assessing its performance.
    \item[\Roman{enumi}III.] Model Visualization: Following modeling, we will provide two graphical representations of the model: an Actual vs. Fitted Plot and a Features-Importance Plot.
    \item[\Roman{enumi}IV.] Model Validation: In this stage, we will apply the model to the testing dataset and rigorously validate its performance by computing relevant metrics.
    \item[\Roman{enumi}V.] Regression Assumptions Check: Finally, we will verify adherence to the core regression assumptions, encompassing linearity, normality, homoscedasticity, independence of residuals, and the absence of multicollinearity among residuals.
\end{enumerate}

  
\section{Split the Dataset}
The following script is used to split the dataset into two different sub-datasets. The first is named \texttt{data\_for\_training}, contains 75% of the observations, and will be used to train the model. The second is named \texttt{data\_for\_testing}, contains the remaining 25% of the observations, and will be used to test the model's performance.

```{r}
# Assign the 'log_price' column in 'y' to the 'log_price' column in 'regression_data'
regression_data$log_price <- y

# Create a data partition for training and testing
split <- createDataPartition(y,
                             times = 1,
                             p = 0.75,
                             list = FALSE)
# Subset the 'regression_data' into 'data_for_training' using the partition
data_for_training <- regression_data[split,]

# Subset the 'regression_data' into 'data_for_testing' using the inverse of the partition
data_for_testing <- regression_data[-split,]

# Print the dimensions of the training and testing datasets
cat("Our training dataset has ", nrow(data_for_training), " observations and ", ncol(data_for_training), " variables, while our testing dataset has ", nrow(data_for_testing), " observations and ", ncol(data_for_testing), " variables.")

```

\section{Regression model training}
In the following section we will walk through all the steps needed to train our XGBoost regression model.

\subsection{Storing the target variable}
The first step for building the regression model is quite simple. We started by storing our target variable (\texttt{log\_price}) in a separate vector named \texttt{y\_train}. Then, we removed the target variable from our training dataset using the select() function from the dplyr package.

```{r}
# Extract the 'log_price' column from the 'data_for_training' dataset and assign it to 'y_train'
y_train <- data_for_training$log_price

# Remove the 'log_price' column from the 'data_for_training' dataset
data_for_training <- data_for_training %>%
  dplyr::select(-log_price)
```


\subsection{Hyperparameters tuning}
The second step is probably the most complicated one. Basically, the following code snippets are use to perform a Hyperparameters tuning for our XGBoost model using the 'caret' package.

\textbf{Hyperparameters} are the settings that configure a machine learning model and that are not learned by the model during the training phase, but instead are set before the training begins. These settings can have a significant impact on the performance of the model, and so finding the best combination of hyperparameters is an important step in the machine learning process. Basically, if we don't explicitly specify these hyperparameters in R, then the model will be trained with default hyperparameters provided by the function we are using (in our case, the \texttt{xgb.train()} function). However, these default hyperparameters may not be optimal for our specific problem, so it's important to carefully consider and set the hyperparameters that suit our needs.

\textbf{Hyperparameter tuning} is the process of selecting the optimal combination of hyperparameters for a machine learning model. This process may be done manually (by trying different random combinations of hyperparameters and comparing the performances of the different resulting trained models), or it may be automated using techniques like grid search or Bayesian optimization.

The best hyperparameters which will be used as default parameters of our final xgboost model, are shown below: 

```{r}
# Define the hyperparameter grid for XGBoost
xgb_grid = expand.grid(
  nrounds = 1000,
  eta = c(0.1, 0.05, 0.01),
  max_depth = c(2, 3, 4, 5, 6),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = c(1, 2, 3, 4, 5),
  subsample = 1
)

# Define the control parameters for the training process
control <- trainControl(method = "cv", number = 5, verboseIter = TRUE)

# Define the path to the .Rds file where the trained model will be saved or loaded from
rds_file_path <- "../../gen/analysis/input/xgb_caret.rds"

# Check if the .Rds file exists
if (file.exists(rds_file_path)) {
  # If it exists, load the xgb_caret object from the .Rds file
  xgb_caret <- readRDS(rds_file_path)
} else {
  # If it doesn't exist, run the code to create xgb_caret
  xgb_caret <- train(x = data_for_training, y = y_train, method = 'xgbTree', trControl = control, tuneGrid = xgb_grid)
  
  # Save the xgb_caret object as an .Rds file for future use
  saveRDS(xgb_caret, file = rds_file_path)
}

```

```{r, include=FALSE}
best_tune <- xgb_caret$bestTune

table_best_hyperparameters <- best_tune %>%
  gt() %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_header(
    title = "Best Hyperparameters")
```

 
```{r, echo=FALSE}
table_best_hyperparameters
```

\subsection{Create the XGB Matrix for the Model}
 The third step is quite simple. The code block below shows how to convert the training dataset into a xgb.DMatrix (that will be named as \texttt{dtrain}), which is the default format used by the xgboost modelling.

```{r}
# Create the XBG.DMatrix
dtrain <- xgb.DMatrix(data = as.matrix(data_for_training), label= y_train)
```


\subsection{Finding the Best Number of Iterations to Optimize the (best) Hyperparameters}
In the fourth step, we performed a cross-validation using the XGBoost package in order to find the best number of iterations to optimize the best hyperparameters found in the previous section.
The subsequent block of code creates a table that displays the best iteration number to optimize the best-performing hyperparameters.
  
```{r}
# Define the hyperparameter from the best_tune object
default_param <- list(
  objective = "reg:squarederror",
  booster = "gbtree",
  eta = best_tune$eta,
  gamma = best_tune$gamma,
  max_depth = best_tune$max_depth,
  min_child_weight = best_tune$min_child_weight,
  subsample = best_tune$subsample,
  colsample_bytree = best_tune$colsample_bytree
)


# Define the path to the saved xgbcv.rds file
xgbcv_path <- "../../gen/analysis/input/xgbcv.rds"

# Check if the xgbcv.rds file exists
if (file.exists(xgbcv_path)) {
  # If it exists, load it into the R environment
  xgbcv <- readRDS(xgbcv_path)
} else {
  # If it doesn't exist, run the xgb.cv code and save the result
  xgbcv <- xgb.cv(
    params = default_param,
    data = dtrain,
    nrounds = 1000,
    nfold = 5,
    showsd = TRUE,
    stratified = TRUE,
    print_every_n = 50,
    early_stopping_rounds = 10,
    maximize = FALSE
  )
  
  # Save the xgbcv object to the specified path
  saveRDS(xgbcv, xgbcv_path)
}
```

```{r, include=FALSE}
best_iteration <- which.min(xgbcv$evaluation_log$test_rmse_mean)
best_rmse <- xgbcv$evaluation_log$test_rmse_mean[best_iteration]
best_iteration_results <- data.frame(iteration = best_iteration, test_rmse_mean = best_rmse)

table_best_iteration <- best_iteration_results %>%
  gt() %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_header(
    title = "Best iteration results"
  )
```

```{r, echo=FALSE}
table_best_iteration
```


\subsection{Model Training with Best Hyperparameters and Best Number of Iterations}
In this section, using the xgb.train() function, the XGBoost regression model is trained, using the best number of iterations and the best hyperparameters found in the previous steps. Then, the model is locally saved as an .rds file for future use.

```{r}

# Define the path to the .Rds file
rds_file_path <- "../../gen/analysis/input/xgb_mod.rds"

# Check if the .Rds file exists
if (file.exists(rds_file_path)) {
  # If it exists, load the xgb_mod object from the .Rds file
  xgb_mod <- readRDS(rds_file_path)
} else {
  # If it doesn't exist, run the code to create xgb_mod
  xgb_mod <- xgb.train(data = dtrain, params=default_param, nrounds = best_iteration_results$iteration)
  
  # Save the xgb_caret object as an .Rds file for future use
  saveRDS(xgb_mod, file = rds_file_path)
}

```


\subsection{Model Performances}
Using DALEX package, an explainer object is created, which takes as input the trained model (\textit{xgb\_mod), the training data (\textit{dtrain}), and the corresponding response variable (\textit{y\_train}).

Then, using this "explainer" object, the three main regression model's performance metrics were extracted from our model:

\textbf{MAD}: the Mean Absolute Deviation is a measure of the average absolute difference between the predicted and actual values of the target variable. Essentially, the lower the MAD value, the better the model performance.
  
\textbf{RMSE}: the Root Mean Square Error is calculated by taking the square root of the average of the squared differences between the predicted and actual values. In simple terms, RMSE measures how much the predicted values of a model deviate from the actual values. The lower the RMSE value, the better the model is at making accurate predictions.
  
\textbf{R-Squared}: R-squared, also known as the coefficient of determination, is a statistical measure that represents the proportion of variance in a dependent variable that is explained by a set of independent variables. In other words, R-squared measures how well the regression line (or curve) fits the data points. A value closer to 1 indicates a better fit of the model to the data.
  
```{r, results='hide'}
# Create an explainer object to analyze the XGBoost model
explainer <- explain(xgb_mod, data = dtrain, y = y_train)

# Calculate model performance measures using the explainer
model_summary <- model_performance(explainer)

# Extract the model performance measures
model_summary_measures <- model_summary$measures

# Convert the model summary measures into a data frame
model_summary_measures <- data.frame(model_summary_measures)

# Remove the 'mse' (Mean Squared Error) column from the data frame
model_summary_measures <- dplyr::select(model_summary_measures, -mse)

``` 

The model's performance metrics are shown below:
```{r, include=FALSE}
# Display the performance metrics:
table_model_performance_metrics_training <- model_summary_measures %>%
  gt() %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_header(
    title = "XGBoost Regression Performance",
    subtitle = "Training Dataset"
  )
```

```{r, echo=FALSE}
table_model_performance_metrics_training
```  
  

\section{Model Visualization}
\subsection{Actual vs. Fitted Price Plot}
Within this section, in order to visually represent our regression model, we have built an Actual vs. Fitted Values Scatterplot using the model fueled with the training dataset.
Basically, we have plotted the actual prices of listings on the x-axis and the predicted (i.e. fitted) prices of listings on the y-axis as a scatter plot and then add the regression line to show the relationship between the actual and predicted values.

```{r, include=FALSE}
model_summary_residuals <- model_summary$residuals
plot_model_visualization <- ggplot(model_summary_residuals, aes(x = observed, y = predicted)) +
  geom_point(color = "darkgrey")+
  geom_smooth(method = "lm", col = "red", se = FALSE, size = 1) +
  labs(x = "Actual Price",
       y = "Predicted Price", 
       title = "Model Visualization") +
  theme(legend.position = "none", 
        plot.title = element_text(size = 18, lineheight=.8, face="bold", vjust=1, hjust=0.5, colour = "black"),
        plot.subtitle = element_text(size = 12, lineheight=.8, vjust=1, hjust=0.5, colour = "black"),
        axis.title = element_text(size = 14, colour = "black"), 
        axis.text = element_text(size = 8, colour = "#666666"),
        axis.text.x = element_text(hjust = 1),
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"))

```

```{r, echo=FALSE}
plot_model_visualization
```

\subsection{Features-Importance Plot}
In this section a Features-Importance Plot was constructed in order to understand the relative contribution of each feature to the model's performance. In particular, we have retain only the first 20 most important variables. 

```{r}
# Calculate feature importance using the xgb.importance function
importance <- xgb.importance(feature_names = colnames(dtrain), model = xgb_mod, data = dtrain, label = y_train)

# Convert the importance results into a data frame
importance <- as.data.frame(importance)

# Remove 'Cover' and 'Frequency' columns from the data frame
importance <- importance %>% dplyr::select(-Cover, -Frequency)

# Round the 'Gain' column values to three decimal places
importance <- dplyr::mutate(importance, Gain = round(Gain, 3))

# Arrange the data frame in descending order based on 'Gain'
importance <- arrange(importance, desc(Gain))

# Select the top 20 rows from the data frame
importance <- dplyr::slice(importance, 1:20)

```

```{r, include=FALSE}
features_importance_plot <- ggplot(data = importance, aes(x = reorder(Feature, Gain), y = Gain, fill = Gain)) +
  geom_bar(stat = "identity") +
  labs(title = "Permutation Importance Plot",
       x = "Feature",
       y = "Importance (Gain)") +
  coord_flip() +
  scale_fill_gradient(low = "lightgrey", high = "black")+
  theme(legend.position = "none", 
        plot.title = element_text(size = 18, lineheight=.8, face="bold", vjust=1, hjust=0.5, colour = "black"),
        plot.subtitle = element_text(size = 12, lineheight=.8, vjust=1, hjust=0.5, colour = "black"),
        axis.title = element_text(size = 14, colour = "black"), 
        axis.text = element_text(size = 8, colour = "#666666"),
        axis.text.x = element_text(hjust = 1),
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"))

``` 

```{r, echo=FALSE}
features_importance_plot
```

\section{Model Validation}
In this section, the trained model was applied to the testing dataset created before. Moreover, in order to have a better overall understanding of our regression model performance, the same performance metrics (RMSE, R-Squared, and MAD) analyzed before with regard to the model fueled with the training dataset were computed again for the model fueled with the testing dataset. 

```{r, results='hide'}

# Extract the 'log_price' column as the target variable for testing
y_test <- data_for_testing$log_price

# Remove the 'log_price' column from the testing data
data_for_testing <- data_for_testing %>%
  dplyr::select (-log_price)

# Create an xgb.DMatrix object from the testing data
dtest <- xgb.DMatrix(data = as.matrix(data_for_testing))

# Use the trained xgboost model to make predictions on the testing data
XGBpred <- predict(xgb_mod, dtest)

# Create an explainer object to analyze the xgboost model's predictions
explainer <- explain(xgb_mod, data = dtest, y = y_test)

# Compute model performance summary measures
model_summary <- model_performance(explainer)

# Extract model summary measures and remove 'mse' column
model_summary_measures <- model_summary$measures
model_summary_measures <- data.frame(model_summary_measures) %>% dplyr::select(-mse)

```

```{r, include=FALSE}
table_model_performance_metrics_testing <- model_summary_measures %>%
  gt() %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())
  ) %>%
  tab_header(
    title = "XGBoost Regression Performance",
    subtitle = "Testing Dataset"
  )
```

```{r, echo=FALSE}
table_model_performance_metrics_testing
```  



\section{Regression Assumptions Check}
Whithin this section, all assumptions of regression models will be assessed. Specifically, the linearity assumption, the normality assumption, the homoscedasticity assumption, the independence of residuals assumption, and the absence of multicollinearity between residuals assumption will be checked.

\subsection{Linearity Assumption}
The 'linearity assumption' assumes that the relationship between the predictors and the target variable is linear. To check the linearity assumption, a (standardized) Residuals vs. Fitted Plot was employed. This plot shows the residuals (difference between the fitted values and actual values) against the fitted values (values predicted by our model).

```{r, include=FALSE}
Actual = y_test
Predicted = XGBpred
Residuals = y_test - XGBpred
Std_Residuals <- scale(y_test - XGBpred)
Sqrt_Std_Residuals <- sqrt(abs(Std_Residuals))

pred_df <- data.frame(Actual, Predicted, Residuals, Std_Residuals, Sqrt_Std_Residuals)
```

As can be seen from below, since the Residuals vs. Fitted Plot shows a random scatter of points, it is possible to state that the linearity relatioships assumption is met. 

```{r, include=FALSE}
plot <- ggplot(pred_df, aes(x = Predicted, y = Std_Residuals)) +
  geom_point(alpha = 0.3, color = "darkgrey")+
  geom_hline(yintercept = 0, linetype = "dashed", col = "red", size = 1) +
  labs(x = "Predicted Price",
       y = "Standardized Residuals", 
       title = "Residual vs. Fitted Values Plot") +
  theme(legend.position = "none", 
        plot.title = element_text(size = 18, lineheight=.8, face="bold", vjust=1, hjust=0.5, colour = "black"),
        plot.subtitle = element_text(size = 12, lineheight=.8, vjust=1, hjust=0.5, colour = "black"),
        axis.title = element_text(size = 14, colour = "black"), 
        axis.text = element_text(size = 8, colour = "#666666"),
        axis.text.x = element_text(hjust = 1),
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"))
```

```{r, echo=FALSE}
plot
```


\subsection{Normality Assumption}
The 'normality of residuals' assumption assumes that the residuals are normally distributed. If the residuals are not normally distributed, their randomness is lost, which implies that the model is not able to explain the relation in the data.

To check the normality assumption, a histogram of the residuals was created to compare the distribution of the residuals to a normal distribution. As can be seen from below, since the histogram of residuals resemble a 'bell-shaped' curve centered around zero, it is possible to state that the assumption of normality of residuals is verified. 

```{r, include=FALSE}

plot <- ggplot(pred_df, aes(Residuals))+
  geom_histogram(col = "black", fill = "darkgrey")+
  scale_x_continuous(n.breaks = 10)+
  labs(x="Residuals",
       y= "Occurrences",
       title = "Histogram of Residuals",
       subtitle = "Residuals follow approximately a Normal Distribution")+
  theme(legend.position = "none", 
        plot.title = element_text(size = 18, lineheight=.8, face="bold", vjust=1, hjust=0.5, colour = "black"),
        plot.subtitle = element_text(size = 12, lineheight=.8, vjust=1, hjust=0.5, colour = "black"),
        axis.title = element_text(size = 14, colour = "black"), 
        axis.text = element_text(size = 8, colour = "#666666"),
        axis.text.x = element_text(angle = 90, hjust = 1),
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"))
```

```{r, echo=FALSE}
plot
```

\subsection{Homoscedasticity Assumption}
The 'homoscedasticity' assumption assumes that the residuals have equal variances (homoscedasticity) for every fitted values. Basically, homoscedasticity is necessary to calculate accurate standard errors for parameter estimates. 

To assess the Homoscedasticity assumption, a Scale Location plot was constructed. In a Scale-Location plot, the square root of the standardized absolute residuals is plotted against the fitted (predicted) values. Since the plot shows a random scatter of points around a horizontal line (parallel to the x-axis) around zero, we can state that the Homoscedasticity assumption is met. 


```{r, include=FALSE}
plot <- ggplot(pred_df, aes(x = Predicted, y = Sqrt_Std_Residuals)) +
  geom_point(color = "darkgrey") +
  geom_smooth(method = "lm", col = "red", se = FALSE, size = 1) +
  labs(x = "Predicted Prices",
       y = "Sqrt(std(residuals))", 
       title = "Scale-Location Plot") +
  theme(legend.position = "none", 
        plot.title = element_text(size = 18, lineheight=.8, face="bold", vjust=1, hjust=0.5, colour = "black"),
        plot.subtitle = element_text(size = 12, lineheight=.8, vjust=1, hjust=0.5, colour = "black"),
        axis.title = element_text(size = 14, colour = "black"), 
        axis.text = element_text(size = 8, colour = "#666666"),
        axis.text.x = element_text(hjust = 1),
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"))

```

```{r, echo=FALSE}
plot
```


\subsection{Independence of Residuals Assumption}
The 'independence of residuals' assumption (absence of autocorrelation between residuals) assumes that residuals are independent to (i.e. uncorrelated with) one anotheer.

To check the independence of residuals assumption, an Autocorrelation Function of Residuals Plot (ACF of Residuals Plot) was built. Since the autocorrelation values (y-axis) are close to zero for almost all lags (x-axis), it is possible to state that this assumption is satisfied.

```{r, include=FALSE}
resid_ts <- ts(pred_df$Residuals)

plot <- ggacf(resid_ts) +
  ggtitle("Autocorrelation Function of Residuals Plot") +
  xlab("Lags") + ylab("Autocorrelation") +
  theme(legend.position = "none", 
        plot.title = element_text(size = 18, lineheight=.8, face="bold", vjust=1, hjust=0.5, colour = "black"),
        plot.subtitle = element_text(size = 12, lineheight=.8, vjust=1, hjust=0.5, colour = "black"),
        axis.title = element_text(size = 14, colour = "black"), 
        axis.text = element_text(size = 8, colour = "#666666"),
        axis.text.x = element_text(hjust = 1),
        panel.grid.major = element_line(color = "gray", size = 0.5),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"))

```

```{r, echo=FALSE}
plot
```

\subsection{Multicollinearity Assumption}
The regression assumption of "Absence of Multicollinearity between Predictors" refers to the absence of strong correlations between the predictor variables in a regression model. In other words, multicollinearity occurs when two or more predictor variables in the model are highly correlated with each other, which can cause problems in the estimation of regression coefficients and the interpretation of the results.

Since the final dataset has more than 200 variables, it would have been almost impossible to construct a scatterplot for each pairs of variables. However, since we have previously removed all those predictors with a mutual correlation greater than 0.75 (see data\_preparation), it is possible to safely state that this last assumption is met, too.



\section{Save relevant objects}
In conclusion, all relevant objects were preserved for future purposes.
```{r}
saveRDS(data_for_training, file = "../../gen/analysis/input/data_for_training.rds")
saveRDS(xgb_mod, file = "../../gen/analysis/input/xgb_mod.rds")
```

```{r, include=FALSE}
rm(list=ls())
```
